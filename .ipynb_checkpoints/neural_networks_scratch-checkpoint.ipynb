{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "7065339f-882d-4a0a-b8a5-46b22d2170bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "7928353d-9229-43e6-857e-9c425ea013b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53943, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('./datasets/diamonds.csv')\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "21bdbcda-df98-4b98-a613-c0941b47dc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53943, 7)\n",
      "Index(['carat', 'depth', 'table', 'price', 'x', 'y', 'z'], dtype='object')\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.198189</td>\n",
       "      <td>-0.174033</td>\n",
       "      <td>-1.099673</td>\n",
       "      <td>-0.904102</td>\n",
       "      <td>-1.587882</td>\n",
       "      <td>-1.536239</td>\n",
       "      <td>-1.571166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.240384</td>\n",
       "      <td>-1.360676</td>\n",
       "      <td>1.585457</td>\n",
       "      <td>-0.904102</td>\n",
       "      <td>-1.641372</td>\n",
       "      <td>-1.658821</td>\n",
       "      <td>-1.741217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.198189</td>\n",
       "      <td>-3.384949</td>\n",
       "      <td>3.375544</td>\n",
       "      <td>-0.903851</td>\n",
       "      <td>-1.498733</td>\n",
       "      <td>-1.457436</td>\n",
       "      <td>-1.741217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.071605</td>\n",
       "      <td>0.454189</td>\n",
       "      <td>0.242892</td>\n",
       "      <td>-0.902096</td>\n",
       "      <td>-1.365010</td>\n",
       "      <td>-1.317342</td>\n",
       "      <td>-1.287749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.029411</td>\n",
       "      <td>1.082412</td>\n",
       "      <td>0.242892</td>\n",
       "      <td>-0.901846</td>\n",
       "      <td>-1.240202</td>\n",
       "      <td>-1.212272</td>\n",
       "      <td>-1.117699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      carat     depth     table     price         x         y         z\n",
       "0 -1.198189 -0.174033 -1.099673 -0.904102 -1.587882 -1.536239 -1.571166\n",
       "1 -1.240384 -1.360676  1.585457 -0.904102 -1.641372 -1.658821 -1.741217\n",
       "2 -1.198189 -3.384949  3.375544 -0.903851 -1.498733 -1.457436 -1.741217\n",
       "3 -1.071605  0.454189  0.242892 -0.902096 -1.365010 -1.317342 -1.287749\n",
       "4 -1.029411  1.082412  0.242892 -0.901846 -1.240202 -1.212272 -1.117699"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definition of orders and label encoding\n",
    "cut_order = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']\n",
    "clarity_order = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']\n",
    "\n",
    "df['cut'] = df['cut'].astype('category')\n",
    "df['cut'] = df['cut'].cat.set_categories(cut_order, ordered=True)\n",
    "df['cut'] = df['cut'].cat.codes\n",
    "\n",
    "df['clarity'] = df['clarity'].astype('category')\n",
    "df['clarity'] = df['clarity'].cat.set_categories(clarity_order, ordered=True)\n",
    "df['clarity'] = df['clarity'].cat.codes\n",
    "\n",
    "# Now use one-hot encoding for color\n",
    "\"\"\"\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "color_encoded = one_hot_encoder.fit_transform(df['color'].values.reshape(-1,1))\n",
    "df_color = pd.DataFrame(color_encoded, columns=one_hot_encoder.get_feature_names_out())\n",
    "\"\"\"\n",
    "\n",
    "# drop the original 'color' column\n",
    "df.drop(['color','cut','clarity'], axis=1, inplace=True)\n",
    "\n",
    "# concat the one-hot encoded 'color' dataframe with the original dataframe\n",
    "#df = pd.concat([df, df_color], axis=1)\n",
    "\n",
    "# scale the other number variables\n",
    "scaler = StandardScaler()\n",
    "df[['carat', 'depth', 'table', 'x', 'y', 'z','price']] = scaler.fit_transform(df[['carat', 'depth', 'table', 'x', 'y', 'z','price']])\n",
    "\n",
    "\"\"\"color_mapping = {\n",
    "    'x0_D': 'color_D',\n",
    "    'x0_E': 'color_E',\n",
    "    'x0_F': 'color_F',\n",
    "    'x0_G': 'color_G',\n",
    "    'x0_H': 'color_H',\n",
    "    'x0_I': 'color_I',\n",
    "    'x0_J': 'color_J',\n",
    "}\n",
    "\n",
    "df.rename(columns=color_mapping, inplace=True)\"\"\"\n",
    "\n",
    "print(df.shape)\n",
    "print(print(df.columns))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "fc763256-c2aa-4cc2-95a2-f10fcbcf701c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53943 53943\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('price', axis=1).values\n",
    "y = df['price'].values\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "4a013db0-5f02-4964-8d6b-cbaec74db94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "4afac5d4-02d9-40ed-bd92-d1b9148a9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def shuffle_data(X, y):\n",
    "    return shuffle(X, y, random_state=0)\n",
    "\n",
    "def create_batches(data, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield i, data[i:i + batch_size]\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, num_inputs ,num_neurons):\n",
    "        self.weights = np.random.normal(0, 0.1, (num_inputs, num_neurons))\n",
    "        self.bias = np.zeros(num_neurons)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output =  inputs @ self.weights + self.bias\n",
    "        \n",
    "    def update_params(self, dweights, dbias, lr):\n",
    "        self.weights -= lr * dweights\n",
    "        self.bias -= lr * dbias\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred))\n",
    "\n",
    "def dev_mse(y_true, y_pred):\n",
    "    return -2 * (y_true - y_pred)\n",
    "\n",
    "#forward propagation\n",
    "#h1 = relu(w1x + b1)\n",
    "#h2 = relu(w2h1 + b2)\n",
    "#o = w3*h2 + b3\n",
    "\n",
    "#cost function\n",
    "# L = 1/n  * Î£(o_i - y_i)^2\n",
    "\n",
    "#backpropagation\n",
    "#dL/do = 2/n*(o - y_actual)\n",
    "#do/dw3 = h2\n",
    "#do/dh2 = w3\n",
    "#dh2/dw2 = h1 if w2h1 + b2 > 0 else 0\n",
    "#dh1/dw1 = x if w1x + b1 > 0 else 0\n",
    "\n",
    "#example equations\n",
    "#dL/dw1 = 2 * (o - y_actual) * w3 * (1 if w2h1 + b2 > 0 else 0) * w2 * (1 if w1x + b1 > 0 else 0) * x\n",
    "\n",
    "#for bias\n",
    "#dL/db1 = dL/do * do/dh2 * dh2/dh1 * dh1/db1\n",
    "#dL/db2 = dL/do * do/dh2 * dh2/db2\n",
    "#dL/db3 = dL/do * do/db3\n",
    "\n",
    "#example equations\n",
    "#dL/db1 = 2*(o - y_actual) * w3 * (1 if w2h1 + b2 > 0 else 0) * w2  * (1 if w1x + b1 > 0 else 0)\n",
    "#dL/db2 = 2*(o - y_actual) * w3 * (1 if w2h1 + b2 > 0 else 0)\n",
    "#dL/db3 = 2(o - y_actual)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "794ba535-98b4-4085-bd9a-7a99f9808b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights shape (4, 16)\n",
      "relu shape (16,)\n",
      "weights shape (16, 8)\n",
      "relu shape (8,)\n",
      "weights shape (8, 1)\n",
      "back output weights (8, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,) and (8,) not aligned: 1 (dim 0) != 8 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n0/1dhxpkfd0fb61spl6grl3vx40000gn/T/ipykernel_97930/3578044557.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdev_reluZ2_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA2_value\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mlayerZ2_back_bias\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mder_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdev_reluZ2_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mlayerZ2_back_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA1_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayerZ2_back_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"back Z2 weights\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayerZ2_back_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayerZ2_back_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,) and (8,) not aligned: 1 (dim 0) != 8 (dim 0)"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2,3,4])\n",
    "layerZ = DenseLayer(len([1,2,3,4]),16)\n",
    "print(\"weights shape\",layerZ.weights.shape)\n",
    "layerZ.forward(X)\n",
    "A1_value = relu(layerZ.output)\n",
    "print(\"relu shape\",A1_value.shape)\n",
    "layerZ2 = DenseLayer(len(A1_value),8)\n",
    "print(\"weights shape\",layerZ2.weights.shape)\n",
    "layerZ2.forward(A1_value)\n",
    "A2_value = relu(layerZ2.output)\n",
    "print(\"relu shape\",A2_value.shape)\n",
    "output = DenseLayer(len(A2_value),1)\n",
    "print(\"weights shape\",output.weights.shape)\n",
    "output.forward(A2_value)\n",
    "\n",
    "#doing backpropagation\n",
    "der_mse = dev_mse([0.5],output.output)\n",
    "output_back_bias = der_mse # scalar\n",
    "output_back_weights = np.outer(A2_value, der_mse)\n",
    "print(\"back output weights\", output_back_weights.shape)\n",
    "\n",
    "dev_reluZ2_bias = np.where(A2_value > 0, 1, 0)\n",
    "layerZ2_back_bias =  np.dot(der_mse, output.weights.T[0]) * dev_reluZ2_bias\n",
    "layerZ2_back_weights = np.outer(A1_value, layerZ2_back_bias) \n",
    "print(\"back Z2 weights\", layerZ2_back_weights.shape, layerZ2_back_bias.shape)\n",
    "\n",
    "dev_reluZ1_bias = np.where(A1_value > 0, 1, 0)\n",
    "layerZ1_back_bias = np.dot(layerZ2_back_bias, layerZ2.weights.T) * dev_reluZ1_bias\n",
    "layerZ1_back_weight = np.outer(X, layerZ1_back_bias)\n",
    "print(\"back Z1 weights\", layerZ1_back_weight.shape, layerZ1_back_bias.shape)\n",
    "\n",
    "# Update weights and biases\n",
    "lr = 0.01  # learning rate\n",
    "layerZ.update_params(layerZ1_back_weight, layerZ1_back_bias, lr)\n",
    "layerZ2.update_params(layerZ2_back_weights, layerZ2_back_bias, lr)\n",
    "output.update_params(output_back_weights, output_back_bias, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "54303b01-6189-4293-9bf8-0ca32aa3a697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.05659965715980727\n",
      "Epoch 2, loss: 0.05711412369277429\n",
      "Epoch 3, loss: 0.05712086998944007\n",
      "Epoch 4, loss: 0.05715956248420158\n",
      "Epoch 5, loss: 0.05717114036536126\n",
      "Epoch 6, loss: 0.05718808536680764\n",
      "Epoch 7, loss: 0.057200583524243884\n",
      "Epoch 8, loss: 0.05720714977514421\n",
      "Epoch 9, loss: 0.05721397559190969\n",
      "Epoch 10, loss: 0.057217722744095326\n",
      "Epoch 11, loss: 0.05722727385562494\n",
      "Epoch 12, loss: 0.05723042023418636\n",
      "Test loss: 1.8871032097175606\n"
     ]
    }
   ],
   "source": [
    "#Defining layer sizes\n",
    "num_inputs = 6\n",
    "num_hidden = 64\n",
    "num_hidden2 = 32\n",
    "num_outputs = 1\n",
    "\n",
    "# Create the layers\n",
    "layer1 = DenseLayer(num_inputs, num_hidden)\n",
    "layer2 = DenseLayer(num_hidden, num_hidden2)\n",
    "output_layer = DenseLayer(num_hidden2, num_outputs)\n",
    "num_epochs = 12\n",
    "# Learning rate\n",
    "lr = 0.01\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for i, batch in create_batches(X_train, 32):\n",
    "        #print(\"batch\",batch.shape)\n",
    "        y_batch = y_train[i:i + len(batch)]\n",
    "        # Forward pass\n",
    "        layer1.forward(batch)\n",
    "        A1 = relu(layer1.output)\n",
    "        #print(\"A1\",A1.shape)\n",
    "        \n",
    "        layer2.forward(A1)\n",
    "        A2 = relu(layer2.output)\n",
    "        \n",
    "        #print(\"A2\",A2.shape)\n",
    "        \n",
    "        output_layer.forward(A2)\n",
    "        y_pred = output_layer.output\n",
    "        #print(\"output\",y_pred.shape)\n",
    "\n",
    "        # Calculate loss\n",
    "        batch_loss = mse(y_batch, y_pred)\n",
    "        epoch_loss += batch_loss\n",
    "\n",
    "        # Backward pass\n",
    "        \n",
    "        # output_layer\n",
    "        der_mse = dev_mse(y_batch, y_pred.reshape(-1))\n",
    "        output_back_bias = np.sum(der_mse, axis=0)\n",
    "        output_back_weights = A2.T @ der_mse\n",
    "        #print(\"output weights\",output_back_weights.shape)\n",
    "        # layer2 \n",
    "        #print(der_mse.shape, output_layer.weights.shape)\n",
    "        dev_h2 = (A2 > 0).astype(float) # ReLU derivative\n",
    "        L2_back_bias = der_mse.reshape(-1, 1) @ output_layer.weights.T * dev_h2\n",
    "        #L2_back_bias = np.sum(L2_back_bias, axis=0) # Sum over batch\n",
    "        #print(\"L2 bias\",L2_back_bias.shape)\n",
    "        L2_back_weights = A1.T @ L2_back_bias / len(A1)\n",
    "        #print(\"L2 weights\",layer2.weights.shape)\n",
    "        # layer1\n",
    "        dev_h1 = (A1 > 0).astype(float) # ReLU derivative\n",
    "        L1_back_bias = L2_back_bias @ layer2.weights.T * dev_h1\n",
    "        #print(\"L1 bias\",L1_back_bias.shape)\n",
    "        L1_back_weights = batch.T @ L1_back_bias / len(batch)\n",
    "        #print(\"L1 weights\",L1_back_weights.shape)\n",
    "        \n",
    "        # Update weights and biases\n",
    "        output_layer.update_params(output_back_weights.reshape(-1, 1),output_back_bias, lr) \n",
    "        layer2.update_params(L2_back_weights,np.sum(L2_back_bias, axis=0),lr)\n",
    "        layer1.update_params(L1_back_weights,np.sum(L1_back_bias, axis=0),lr)\n",
    "        #print(\"i\",i, epoch_loss)\n",
    "        \n",
    "            \n",
    "\n",
    "    print(f'Epoch {epoch+1}, loss: {epoch_loss/len(X_train)}')\n",
    "\n",
    "# Test the model\n",
    "layer1.forward(X_test)\n",
    "A1 = relu(layer1.output)\n",
    "\n",
    "layer2.forward(A1)\n",
    "A2 = relu(layer2.output)\n",
    "\n",
    "output_layer.forward(A2)\n",
    "y_pred = output_layer.output\n",
    "\n",
    "test_loss = mse(y_test, y_pred)\n",
    "print(f'Test loss: {test_loss}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "671276d7-3851-4472-9afd-8cd8d8d3aad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.06889101\n",
      "Iteration 2, loss = 0.06311986\n",
      "Iteration 3, loss = 0.06186622\n",
      "Iteration 4, loss = 0.06212780\n",
      "Iteration 5, loss = 0.06092901\n",
      "Iteration 6, loss = 0.06053496\n",
      "Iteration 7, loss = 0.05989047\n",
      "Iteration 8, loss = 0.05993571\n",
      "Iteration 9, loss = 0.05937296\n",
      "Iteration 10, loss = 0.05938943\n",
      "Iteration 11, loss = 0.05912356\n",
      "Iteration 12, loss = 0.05911808\n",
      "Iteration 13, loss = 0.05882332\n",
      "Iteration 14, loss = 0.05879753\n",
      "Iteration 15, loss = 0.05870347\n",
      "Iteration 16, loss = 0.05872644\n",
      "Iteration 17, loss = 0.05851157\n",
      "Iteration 18, loss = 0.05848061\n",
      "Iteration 19, loss = 0.05830786\n",
      "Iteration 20, loss = 0.05841894\n",
      "Iteration 21, loss = 0.05838787\n",
      "Iteration 22, loss = 0.05841800\n",
      "Iteration 23, loss = 0.05810619\n",
      "Iteration 24, loss = 0.05821441\n",
      "Iteration 25, loss = 0.05800304\n",
      "Iteration 26, loss = 0.05815076\n",
      "Iteration 27, loss = 0.05794808\n",
      "Iteration 28, loss = 0.05799040\n",
      "Iteration 29, loss = 0.05792071\n",
      "Iteration 30, loss = 0.05786458\n",
      "Iteration 31, loss = 0.05791078\n",
      "Iteration 32, loss = 0.05774847\n",
      "Iteration 33, loss = 0.05781761\n",
      "Iteration 34, loss = 0.05780447\n",
      "Iteration 35, loss = 0.05776671\n",
      "Iteration 36, loss = 0.05775471\n",
      "Iteration 37, loss = 0.05768355\n",
      "Iteration 38, loss = 0.05780995\n",
      "Iteration 39, loss = 0.05773308\n",
      "Iteration 40, loss = 0.05768908\n",
      "Iteration 41, loss = 0.05761686\n",
      "Iteration 42, loss = 0.05745372\n",
      "Iteration 43, loss = 0.05737355\n",
      "Iteration 44, loss = 0.05776111\n",
      "Iteration 45, loss = 0.05762065\n",
      "Iteration 46, loss = 0.05765179\n",
      "Iteration 47, loss = 0.05753974\n",
      "Iteration 48, loss = 0.05745537\n",
      "Iteration 49, loss = 0.05740693\n",
      "Iteration 50, loss = 0.05754411\n",
      "Iteration 51, loss = 0.05727204\n",
      "Iteration 52, loss = 0.05730888\n",
      "Iteration 53, loss = 0.05745189\n",
      "Iteration 54, loss = 0.05738826\n",
      "Iteration 55, loss = 0.05744562\n",
      "Iteration 56, loss = 0.05741431\n",
      "Iteration 57, loss = 0.05746595\n",
      "Iteration 58, loss = 0.05735873\n",
      "Iteration 59, loss = 0.05737586\n",
      "Iteration 60, loss = 0.05725953\n",
      "Iteration 61, loss = 0.05725489\n",
      "Iteration 62, loss = 0.05717208\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('mlpregressor',\n",
       "                 MLPRegressor(batch_size=32, hidden_layer_sizes=(64, 32),\n",
       "                              learning_rate='adaptive', max_iter=100,\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# create a StandardScaler to normalize the input features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create the MLPRegressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', \n",
    "                   learning_rate='adaptive', max_iter=100, batch_size=32, verbose=True)\n",
    "\n",
    "# create a pipeline that first normalizes the input features and then fits the MLPRegressor\n",
    "model = make_pipeline(scaler, mlp)\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1906f9-4219-40c9-9cf5-fd16dff8f8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
